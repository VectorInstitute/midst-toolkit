# Ensemble example configuration
# Base data directory (can be overridden from command line)
base_data_dir: examples/ensemble_attack/data
base_example_dir: examples/ensemble_attack

# Data paths (relative to base_data_dir)
data_paths:
  midst_data_path: ${base_data_dir}/midst_data_all_attacks # Used only for reading the data
  population_path: ${base_data_dir}/population_data  # Path where the population data should be stored
  processed_attack_data_path: ${base_data_dir}/attack_data # Path where the processed attack real train and evaluation data is stored

# Pipeline control
pipeline:
  run_data_processing: false # Set this to false if you have already saved the processed data
  run_shadow_model_training: True

# Dataset specific information used for processing in this example
data_processing_config:
  collect_attack_data_types:
          [
            "tabddpm_black_box",
            "tabsyn_black_box",
            "tabddpm_white_box",
            "tabsyn_white_box",
            "clavaddpm_black_box",
            "clavaddpm_white_box",
        ]
  # The column name in the data to be used for stratified splitting.
  column_to_stratify: "trans_type"  # Attention: This value is not documented in the original codebase.
  folder_ranges:
    train: [[1, 31]]
    dev: [[51, 61], [91, 101]]
    final: [[61, 71], [101, 111]]
  # File names in MIDST data directories.
  single_table_train_data_file_name: "train_with_id.csv"
  multi_table_train_data_file_name: "trans.csv"
  challenge_data_file_name: "challenge_with_id.csv"
  population_sample_size: 30

# Training and data settings for shadow models
shadow_training:
  # Data Config files path used for training a TabDDPM model
  training_json_config_paths: # Config json files used for tabddpm training on the trans table
    trans_domain_file_path: ${base_example_dir}/data_configs/trans_domain.json
    dataset_meta_file_path: ${base_example_dir}/data_configs/dataset_meta.json
    tabddpm_training_config_path: ${base_example_dir}/data_configs/trans.json
  # Model training artifacts are saved under shadow_models_data_path/workspace_name/exp_name
  # Also, training configs for each shadow model are created under shadow_models_data_path.
  shadow_models_data_path: ${base_data_dir}/shadow_models_data
  fine_tune_diffusion_iterations: 2
  fine_tune_classifier_iterations: 2
  num_synth_samples: 3 # Original code:20000
  model_type: "tabddpm"
  pre_train_data_size: 10 #10 for test run. Original code: 60000



# General settings
random_seed: 42
